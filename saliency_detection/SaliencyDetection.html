<!DOCTYPE html>
<html>
  <title>Saliency Detection</title>

  <head>
    <meta charset="UTF-8" />
    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon" />
    <link
      rel="stylesheet"
      href="https://unpkg.com/element-ui/lib/theme-chalk/index.css"
    />
    <link rel="stylesheet" href="../css/index.css" />
    <script src="https://unpkg.com/vue/dist/vue.js"></script>
    <script src="https://unpkg.com/element-ui/lib/index.js"></script>
    <script src="https://unpkg.com/axios/dist/axios.min.js"></script>
  </head>

  <body>
    <div id="app">
      <el-page-header @back="goBack" title="Back"> </el-page-header>
      <!-- Saliency Detection -->
      <div class="content">
        <h1>
          Saliency Detection
        </h1>
        <el-divider></el-divider>
        <p>
          The human visual system can quickly identify regions in a scene that
          attract our attention.Â In this project, we are developing techniques
          to automatically detect salient objects from the input images and
          video.
        </p>
        <el-divider></el-divider>
        <div v-for="project,index in projects">
          <p style="background-color: rgb(242, 244, 225);">
            <span
              v-html="textBold(project.authors)"
              style="font-size: 14px;"
            ></span>
            <b style="font-size: 18px;">{{project.title}}</b>
            <span v-for="tag in project.tags" :style="styles[tag[1]]"
              >{{tag[0]}}</span
            >
            <span v-for="link in project.links"
              >[<b
                ><a style="color: #006699; font-size: 18px;" :href="link.link"
                  >{{link.name}}</a
                ></b
              ><span>]&nbsp;</span></span
            >
          </p>
          <div v-for="img in project.imgs" style="text-align: center;">
            <img :src="'figures/'+img" :alt="img" class="figure_img" />
          </div>
          <div v-if="project.abstract">
            <p><b>Abstract.&nbsp;</b>{{project.abstract}}<span></span></p>
          </div>
          <div v-if="project.io">
            <p><b>Input-Output:&nbsp;</b>{{project.abstract}}<span></span></p>
          </div>
          <el-divider content-position="right">{{index+1}}</el-divider>
        </div>
      </div>
    </div>
  </body>
  <script src="../js/index.js"></script>
  <script>
    new Vue({
      el: '#app',
      data: function () {
        return {
          ks,
          styles,
          projects: [
            {
              authors: 'Xin Tian, Ke Xu, Xin Yang, Baocai Yin, Rynson Lau.',
              title: 'Weakly-supervised Salient Instance Detection.',
              tags: [
                ['BMVC 2020', 1],
                ['. ', 0],
                ['(Oral, 5%)', 2],
              ],
              abstract:
                'Existing salient instance detection (SID) methods typically learn from pixel-level annotated datasets. In this paper, we present the first weakly-supervised approach to the SID problem. Although weak supervision has been considered in general saliency detection, it is mainly based on using class labels for object localization. However, it is non-trivial to use only class labels to learn instance-aware saliency information, as salient instances with high semantic affinities may not be easily separated by the labels. We note that subitizing information provides an instant judgement on the number of salient items, which naturally relates to detecting salient instances and may help separate instances of the same class while grouping different parts of the same instance. Inspired by this insight, we propose to use class and subitizing labels as weak supervision for the SID problem. We propose a novel weakly-supervised network with three branches: a Saliency Detection Branch leveraging class consistency information to locate candidate objects; a Boundary Detection Branch exploiting class discrepancy information to delineate object boundaries; and a Centroid Detection Branch using subitizing information to detect salient instance centroids. This complementary information is further fused to produce salient instance maps. We conduct extensive experiments to demonstrate that the proposed method plays favorably against carefully designed baseline methods adapted from related tasks. ',
              links: [],
              imgs: ['Weakly-supervised Salient Instance Detection.png'],
            },
            {
              authors:
                'Shimin Zhao, Miaomiao Chen, Pengjie Wang, Ying Cao, Pingping Zhang and Xin Yang.',
              title:
                'RGB-D Salient Object Detection via Deep Fusion of Semantics and Details.',
              tags: [
                ['Journal of Computer Animation and Virtual Worlds', 1],
                [', Bournemouth, UK. ', 0],
                ['(Special Issue of CASA 2020)', 1],
              ],
              imgs: [
                'RGB-D Salient Object Detection via Deep Fusion of Semantics and Details.png',
              ],
            },
            {
              authors:
                'Sucheng Ren, Chu Han, Xin Yang, Guoqiang Han, Shengfeng He.',
              title:
                'TENet: Triple Excitation Network for Video Salient Object Detection.',
              tags: [
                ['ECCV 2020', 1],
                [', Glasgow, UK. ', 0],
                ['(Spotlight)', 1],
              ],
              imgs: [
                'Triple Excitation Network for Video Salient Object Detection.png',
              ],
            },
          ],
        }
      },
      methods: {
        textBold(s) {
          for (var i = 0; i < this.ks.length; ++i) {
            const k = this.ks[i]
            if (s.indexOf(k) != -1) return s.replace(k, '<b>' + k + '</b>')
          }
          return s
        },
        goBack() {
          window.location.href = '../index.html#Research Projects'
        },
      },
    })
  </script>
</html>
