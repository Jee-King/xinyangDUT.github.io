

<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="Generator" content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@SimSun";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:10.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{color:purple;
	text-decoration:underline;}
p.MsoAcetate, li.MsoAcetate, div.MsoAcetate
	{mso-style-link:"Balloon Text Char";
	margin:0in;
	margin-bottom:.0001pt;
	font-size:8.0pt;
	font-family:"Tahoma",sans-serif;}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:10.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
p.MsoListParagraphCxSpFirst, li.MsoListParagraphCxSpFirst, div.MsoListParagraphCxSpFirst
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
p.MsoListParagraphCxSpMiddle, li.MsoListParagraphCxSpMiddle, div.MsoListParagraphCxSpMiddle
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
p.MsoListParagraphCxSpLast, li.MsoListParagraphCxSpLast, div.MsoListParagraphCxSpLast
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:10.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
span.BalloonTextChar
	{mso-style-name:"Balloon Text Char";
	mso-style-link:"Balloon Text";
	font-family:"Tahoma",sans-serif;}
.MsoChpDefault
	{font-family:"Calibri",sans-serif;}
.MsoPapDefault
	{margin-bottom:10.0pt;
	line-height:115%;}
 /* Page Definitions */
 @page WordSection1
	{size:11.0in 17.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>

<style type="text/css">@media print{div[id*="composai"] *{display:none !important}}
</style><style data-styled="" data-styled-version="4.3.2"></style></head>

<body lang="EN-US" link="blue" vlink="purple" data-gr-c-s-loaded="true">

<div class="WordSection1">

<div align="center">

<table class="MsoTableGrid" border="1" cellspacing="0" cellpadding="0" width="100%" style="width:100.0%;border-collapse:collapse;border:none">
 <tbody><tr>
  <td width="100%" valign="top" style="width:100.0%;border:none;border-bottom:
  solid windowtext 1.5pt;padding:0in 5.4pt 0in 5.4pt">
  <p class="MsoNormal" align="center" style="margin-top:6.0pt;margin-right:0in;
  margin-bottom:12.0pt;margin-left:0in;text-align:center;line-height:normal"><b><span style="font-size:18.0pt;font-family:&quot;Times New Roman&quot;,serif">Image-based 3D Indoor Scene Modeling
  </span></b></p>
  </td>
 </tr>
 <tr>
  <td width="100%" valign="top" style="width:100.0%;border:none;border-bottom:
  solid windowtext 1.5pt;padding:0in 5.4pt 0in 5.4pt">
  <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;line-height:
  normal"><span style="font-size:12.0pt;font-family:&quot;Times New Roman&quot;,serif">&nbsp;</span></p>
  <p class="MsoNormal" style="margin-bottom:10.0pt;text-align:justify;text-justify:
  inter-ideograph;line-height:115%"><span style="font-size:12.0pt;line-height:
  115%;font-family:&quot;Times New Roman&quot;,serif">Image-based 3D indoor scene reconstruction is widely used in different areas, such as robotic navigation, virtual reality and interior design. The goal of this task is to use as little as possible images as input and output high-quality 3D indoor scene models, expressed as voxel grid, point cloud or triangle mesh. In particular for object reconstruction or local scene completion, it is better to take single image as the whole taskâ€™s input, and for whole scene reconstruction task, less number of inputs would save mobile costs for sensors. Unfortunately, the information provided by 2D images is lacking for what is needed for 3D scene modeling tasks because of the huge gap between 2D domain to 3D domain. Thus traditional methods always use multi-view images as input to solve this problem. </span></p>
  <p class="MsoNormal" style="margin-bottom:10.0pt;text-align:justify;text-justify:
  inter-ideograph;line-height:115%"><span style="font-size:12.0pt;line-height:
  115%;font-family:&quot;Times New Roman&quot;,serif">In this project, we are developing techniques to tackle this problem by dividing it into different related sub-problems. A whole indoor scene can be composed of a series of local scenes, and a local scene can be composed of a series of objects. Based on the above observations, we first address the object reconstruction problem guided by a active view planner, and we then propose a deep reinforcement learning method for local point scene reconstruction from a single depth image. We are currently working on fast and accurate whole scene reconstruction.</span></p>
  </td>
 </tr>
 <tr>
  <td width="100%" valign="top" style="width:100.0%;border:none;border-bottom:
  solid windowtext 1.5pt;padding:0in 5.4pt 0in 5.4pt">
  <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100.0%;border-collapse:collapse;border:none">
   <tbody><tr>
    <td width="100%" valign="top" style="width:100.0%;padding:0in 5.4pt 0in 5.4pt">
    <p class="MsoNormal" style="margin-top:6.0pt;margin-right:0in;margin-bottom:
    0in;margin-left:0in;margin-bottom:.0001pt;line-height:normal"><b><span style="font-family:&quot;Times New Roman&quot;,serif">Deep Reinforcement Learning of Volume-guided Progressive View Inpainting for 3D Point Scene Completion from a Single Depth Image</span></b><span style="font-family:
    &quot;Times New Roman&quot;,serif"> </span><span style="font-size:10.0pt;font-family:
    &quot;Times New Roman&quot;,serif">[</span><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Han_Deep_Reinforcement_Learning_of_Volume-Guided_Progressive_View_Inpainting_for_3D_CVPR_2019_paper.pdf"><span style="font-size:10.0pt;
    font-family:&quot;Times New Roman&quot;,serif">paper</span></a><span style="font-size:10.0pt;font-family:&quot;Times New Roman&quot;,serif">] 
    [<a href="">supply</a>][<a href="">code</a>]
    </span></p>
    <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;
    line-height:normal"><span style="font-size:10.0pt;font-family:&quot;Times New Roman&quot;,serif">Xiaoguang Han, Zhaoxuan Zhang, Dong Du, Mingdai Yang, Jingming Yu, Pan Pan, Xin Yang, Ligang Liu, Zixiang Xiong and Shuguang Cui  </span></p>
    <p class="MsoNormal" style="margin-bottom:6.0pt;line-height:normal"><b><i><span style="font-family:&quot;Times New Roman&quot;,serif;color:#C00000">Proc. IEEE CVPR(oral, CCF A)</span></i></b><span style="font-family:&quot;Times New Roman&quot;,serif">&nbsp;&nbsp;&nbsp;&nbsp; June 2019</span></p>
    </td>
   </tr>
   <tr>
    <td width="100%" valign="top" style="width:100.0%;padding:0in 5.4pt 0in 5.4pt">
    <div align="center">
    <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0" style="border-collapse:collapse;border:none">
     <tbody><tr style="height:142.8pt">
      <td width="751" valign="top" style="width:513.45pt;padding:0in 5.4pt 0in 5.4pt;
      height:142.8pt">
      <p class="MsoNormal" align="center" style="margin-bottom:0in;margin-bottom:
      .0001pt;text-align:center;line-height:normal"><img border="0" width="737" height="578" src="figures/cvpr19_oral_pipeline.png" title="" style="outline: red dashed 1px;"></p>
      <p class="MsoNormal" style="margin-top:0in;margin-right:-2.9pt;margin-bottom:
      0in;margin-left:0in;margin-bottom:.0001pt;text-align:justify;text-justify:
      inter-ideograph;line-height:normal; padding-left: 40%;"><span style="font-size:9.0pt;
      font-family:&quot;Times New Roman&quot;,serif">Overview of proposed framework.</span></p><br/>
      </td>
     </tr>

     <tr style="height:142.8pt">
        <td width="751" valign="top" style="width:513.45pt;padding:0in 5.4pt 0in 5.4pt;
        height:142.8pt">
        <p class="MsoNormal" align="center" style="margin-bottom:0in;margin-bottom:
        .0001pt;text-align:center;line-height:normal"><img border="0" width="737" height="578" src="figures/cvpr19_oral_results.png" title="" style="outline: red dashed 1px;"></p>
        <p class="MsoNormal" style="margin-top:0in;margin-right:-2.9pt;margin-bottom:
        0in;margin-left:0in;margin-bottom:.0001pt;text-align:justify;text-justify:
        inter-ideograph;line-height:normal;"><span style="font-size:9.0pt;
        font-family:&quot;Times New Roman&quot;,serif">Visual comparison of our results
        with those of the state-of-the-art methods. Please zoom in to see the details. </span></p>
        </td>
       </tr>
    </tbody></table>
    </div>
    <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;
    line-height:normal;text-autospace:none"></p>
    </td>
   </tr>
   <tr>
    <td width="100%" valign="top" style="width:100.0%;padding:0in 5.4pt 0in 5.4pt">
    <p class="MsoNormal" style="margin-top:6.0pt;margin-right:0in;margin-bottom:
    6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph;
    line-height:normal;text-autospace:none"><b><span style="font-family:&quot;Times New Roman&quot;,serif">Input-Output:
    </span></b><span style="font-family:&quot;Times New Roman&quot;,serif">Given an single depth image, our method progressively generate the missing points of the initial point cloud corresponding to the input depth map under the optimal sequence of viewpoints.</span></p>
    <p class="MsoNormal" style="margin-top:6.0pt;margin-right:0in;margin-bottom:
    6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph;
    line-height:normal;text-autospace:none"><b><span style="font-family:&quot;Times New Roman&quot;,serif">Abstract.</span></b><span style="font-family:&quot;Times New Roman&quot;,serif"> We present a deep reinforcement learning method of progressive view inpainting for 3D point scene completion under volume guidance, achieving high-quality scene reconstruction from only a single depth image with severe occlusion. Our approach is end-to-end, consisting of three modules: 3D scene volume reconstruction, 2D depth map inpainting, and multi-view selection for completion. Given a single depth image, our method first goes through the 3D volume branch to obtain a volumetric scene reconstruction as a guide to the next view inpainting step, which attempts to make up the missing information; the third step involves projecting the volume under the same view of the input, concatenating them to complete the current view depth, and integrating all depth into the point cloud. Since the occluded areas are unavailable, we resort to a deep Q-Network to glance around and pick the next best view for large hole completion progressively until a scene is adequately reconstructed while guaranteeing validity. All steps are learned jointly to achieve robust and consistent results. We perform qualitative and quantitative evaluations with extensive experiments on the SUNCG data, obtaining better results than the state of the art.  </td>
   </tr>
  </tbody></table>
  <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;line-height:
  normal"></p>
  </td>
 </tr>
 <!-- another paper -->
 <tr>
  <td width="100%" valign="top" style="width:100.0%;border:none;border-bottom:
  solid windowtext 1.5pt;padding:0in 5.4pt 0in 5.4pt">
  <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100.0%;border-collapse:collapse;border:none">
   <tbody><tr>
    <td width="100%" valign="top" style="width:100.0%;padding:0in 5.4pt 0in 5.4pt">
    <p class="MsoNormal" style="margin-top:6.0pt;margin-right:0in;margin-bottom:
    0in;margin-left:0in;margin-bottom:.0001pt;line-height:normal"><b><span style="font-family:&quot;Times New Roman&quot;,serif">Active Object Reconstruction Using a Guided View Planner</span></b><span style="font-family:
    &quot;Times New Roman&quot;,serif"> </span><span style="font-size:10.0pt;font-family:
    &quot;Times New Roman&quot;,serif">[</span><a href="https://arxiv.org/pdf/1805.03081.pdf"><span style="font-size:10.0pt;
    font-family:&quot;Times New Roman&quot;,serif">paper</span></a><span style="font-size:10.0pt;font-family:&quot;Times New Roman&quot;,serif">] 
    [<a href="">supply</a>][<a href="">code</a>]
    </span></p>
    <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;
    line-height:normal"><span style="font-size:10.0pt;font-family:&quot;Times New Roman&quot;,serif">Xin Yang, Yuanbo Wang, Yaru Wang, Bacai Yin, Qian Zhang, Xiaopeng Wei and Hongbo Fu  </span></p>
    <p class="MsoNormal" style="margin-bottom:6.0pt;line-height:normal"><b><i><span style="font-family:&quot;Times New Roman&quot;,serif;color:#C00000">IJCAI(CCF A)</span></i></b><span style="font-family:&quot;Times New Roman&quot;,serif">&nbsp;&nbsp;&nbsp;&nbsp; July 2018</span></p>
    </td>
   </tr>
   <tr>
    <td width="100%" valign="top" style="width:100.0%;padding:0in 5.4pt 0in 5.4pt">
    <div align="center">
    <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0" style="border-collapse:collapse;border:none">
     <tbody><tr style="height:142.8pt">
      <td width="751" valign="top" style="width:513.45pt;padding:0in 5.4pt 0in 5.4pt;
      height:142.8pt">
      <p class="MsoNormal" align="center" style="margin-bottom:0in;margin-bottom:
      .0001pt;text-align:center;line-height:normal"><img border="0" width="737" height="578" src="figures/ijcai18_pipeline.png" title="" style="outline: red dashed 1px;"></p>
      <p class="MsoNormal" style="margin-top:0in;margin-right:-2.9pt;margin-bottom:
      0in;margin-left:0in;margin-bottom:.0001pt;text-align:justify;text-justify:
      inter-ideograph;line-height:normal; padding-left: 40%;"><span style="font-size:9.0pt;
      font-family:&quot;Times New Roman&quot;,serif">Overview of proposed framework.</span></p><br/>
      </td>
     </tr>

     <tr style="height:142.8pt">
        <td width="751" valign="top" style="width:513.45pt;padding:0in 5.4pt 0in 5.4pt;
        height:142.8pt">
        <p class="MsoNormal" align="center" style="margin-bottom:0in;margin-bottom:
        .0001pt;text-align:center;line-height:normal"><img border="0" width="737" height="578" src="figures/ijcai18_results.png" title="" style="outline: red dashed 1px;"></p>
        <p class="MsoNormal" style="margin-top:0in;margin-right:-2.9pt;margin-bottom:
        0in;margin-left:0in;margin-bottom:.0001pt;text-align:justify;text-justify:
        inter-ideograph;line-height:normal;"><span style="font-size:9.0pt;
        font-family:&quot;Times New Roman&quot;,serif">Visual comparison of our results
        with those of the state-of-the-art methods. Please zoom in to see the details. </span></p>
        </td>
       </tr>
    </tbody></table>
    </div>
    <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;
    line-height:normal;text-autospace:none"></p>
    </td>
   </tr>
   <tr>
    <td width="100%" valign="top" style="width:100.0%;padding:0in 5.4pt 0in 5.4pt">
    <p class="MsoNormal" style="margin-top:6.0pt;margin-right:0in;margin-bottom:
    6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph;
    line-height:normal;text-autospace:none"><b><span style="font-family:&quot;Times New Roman&quot;,serif">Input-Output:
    </span></b><span style="font-family:&quot;Times New Roman&quot;,serif">Given a random view image of the target object, our network reconstruct the 3D volume of the object and decide the next best view according to the current reconstruction quality.</span></p>
    <p class="MsoNormal" style="margin-top:6.0pt;margin-right:0in;margin-bottom:
    6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph;
    line-height:normal;text-autospace:none"><b><span style="font-family:&quot;Times New Roman&quot;,serif">Abstract.</span></b><span style="font-family:&quot;Times New Roman&quot;,serif"> Inspired by the recent advance of image-based object reconstruction using deep learning, we present an active reconstruction model using a guided view planner. We aim to reconstruct a 3D model using images observed from a planned sequence of informative and discriminative views. But where are such informative and discriminative views around an object? To address this we propose a unified model for view planning and object reconstruction, which is utilized to learn a guided information acquisition model and to aggregate information from a sequence of images for reconstruction. Experiments show that our model (1) increases our reconstruction accuracy with an increasing number of views (2) and generally predicts a more informative sequence of views for object reconstruction compared to other alternative methods.  </td>
   </tr>
  </tbody></table>
  <p class="MsoNormal" style="margin-bottom:0in;margin-bottom:.0001pt;line-height:
  normal"></p>
  </td>
 </tr>
 <!-- another paper -->
</tbody>
</table>
</div>
<p class="MsoNormal" style="margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:0in;margin-bottom:.0001pt"><i><span style="font-size:9.0pt;
line-height:115%;font-family:&quot;Times New Roman&quot;,serif">Last updated in June
2020</span></i></p>

</div>




<div id="composai-root"><div id="composai-app"></div></div><div id="ycce-container" style="font-family: -apple-system,system-ui,BlinkMacSystemFont,&#39;Segoe UI&#39;,Roboto,&#39;Helvetica Neue&#39;,Arial,sans-serif;font-size: 14px;font-weight: 400;line-height: 1.5;color: #292b2c;background-color: #fff;margin: 0;"></div></body><div id="composai-cards" style="position: absolute; top: 0px; left: 0px;"></div></html>
