<html>
<title>Low-light Image Analysis</title>

<head>
  <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon" />
  <link rel="stylesheet" href="https://unpkg.com/element-ui/lib/theme-chalk/index.css" />
  <script src="https://unpkg.com/vue/dist/vue.js"></script>
  <script src="https://unpkg.com/element-ui/lib/index.js"></script>
  <script src="https://unpkg.com/axios/dist/axios.min.js"></script>
  <style>
    <!--
    /* Font Definitions */
    @font-face {
      font-family: Wingdings;
      panose-1: 5 0 0 0 0 0 0 0 0 0;
    }

    @font-face {
      font-family: SimSun;
      panose-1: 2 1 6 0 3 1 1 1 1 1;
    }

    @font-face {
      font-family: "Cambria Math";
      panose-1: 2 4 5 3 5 4 6 3 2 4;
    }

    @font-face {
      font-family: Calibri;
      panose-1: 2 15 5 2 2 2 4 3 2 4;
    }

    @font-face {
      font-family: Tahoma;
      panose-1: 2 11 6 4 3 5 4 4 2 4;
    }

    @font-face {
      font-family: "\@SimSun";
      panose-1: 2 1 6 0 3 1 1 1 1 1;
    }

    /* Style Definitions */
    p.MsoNormal,
    li.MsoNormal,
    div.MsoNormal {
      margin-top: 0in;
      margin-right: 0in;
      margin-bottom: 10.0pt;
      margin-left: 0in;
      line-height: 115%;
      font-size: 11.0pt;
      font-family: "Calibri", sans-serif;
    }

    a:link,
    span.MsoHyperlink {
      color: blue;
      text-decoration: underline;
    }

    a:visited,
    span.MsoHyperlinkFollowed {
      color: purple;
      text-decoration: underline;
    }

    p.MsoAcetate,
    li.MsoAcetate,
    div.MsoAcetate {
      mso-style-link: "Balloon Text Char";
      margin: 0in;
      margin-bottom: .0001pt;
      font-size: 8.0pt;
      font-family: "Tahoma", sans-serif;
    }

    p.MsoListParagraph,
    li.MsoListParagraph,
    div.MsoListParagraph {
      margin-top: 0in;
      margin-right: 0in;
      margin-bottom: 10.0pt;
      margin-left: .5in;
      line-height: 115%;
      font-size: 11.0pt;
      font-family: "Calibri", sans-serif;
    }

    p.MsoListParagraphCxSpFirst,
    li.MsoListParagraphCxSpFirst,
    div.MsoListParagraphCxSpFirst {
      margin-top: 0in;
      margin-right: 0in;
      margin-bottom: 0in;
      margin-left: .5in;
      margin-bottom: .0001pt;
      line-height: 115%;
      font-size: 11.0pt;
      font-family: "Calibri", sans-serif;
    }

    p.MsoListParagraphCxSpMiddle,
    li.MsoListParagraphCxSpMiddle,
    div.MsoListParagraphCxSpMiddle {
      margin-top: 0in;
      margin-right: 0in;
      margin-bottom: 0in;
      margin-left: .5in;
      margin-bottom: .0001pt;
      line-height: 115%;
      font-size: 11.0pt;
      font-family: "Calibri", sans-serif;
    }

    p.MsoListParagraphCxSpLast,
    li.MsoListParagraphCxSpLast,
    div.MsoListParagraphCxSpLast {
      margin-top: 0in;
      margin-right: 0in;
      margin-bottom: 10.0pt;
      margin-left: .5in;
      line-height: 115%;
      font-size: 11.0pt;
      font-family: "Calibri", sans-serif;
    }

    span.BalloonTextChar {
      mso-style-name: "Balloon Text Char";
      mso-style-link: "Balloon Text";
      font-family: "Tahoma", sans-serif;
    }

    .MsoChpDefault {
      font-family: "Calibri", sans-serif;
    }

    .MsoPapDefault {
      margin-bottom: 10.0pt;
      line-height: 115%;
    }

    /* Page Definitions */
    @page WordSection1 {
      size: 11.0in 17.0in;
      margin: 1.0in 1.0in 1.0in 1.0in;
    }

    div.WordSection1 {
      page: WordSection1;
    }

    /* List Definitions */
    ol {
      margin-bottom: 0in;
    }

    ul {
      margin-bottom: 0in;
    }
    -->
  </style>
</head>

<body lang="EN-US" link="blue" vlink="purple">
  <div id="app" class="WordSection1">
    <el-page-header @back="goBack" title="Back"> </el-page-header>
    <div align="center">
      <table class="MsoTableGrid" border="1" cellspacing="0" cellpadding="0" width="100%"
        style="width: 100%; border-collapse: collapse; border: none;">
        <tr>
          <td width="100%" valign="top" style="
                width: 100%;
                border: none;
                border-bottom: solid windowtext 1.5pt;
                padding: 0in 5.4pt 0in 5.4pt;
              ">
            <p class="MsoNormal" align="center" style="
                  margin-top: 6pt;
                  margin-right: 0in;
                  margin-bottom: 12pt;
                  margin-left: 0in;
                  text-align: center;
                  line-height: normal;
                ">
              <b><span style="
                      font-size: 18pt;
                      font-family: 'Times New Roman', serif;
                    ">Low-light Image Analysis</span></b>
            </p>
          </td>
        </tr>
        <tr>
          <td width="100%" valign="top" style="
                width: 100%;
                border: none;
                border-bottom: solid windowtext 1.5pt;
                padding: 0in 5.4pt 0in 5.4pt;
              ">
            <p class="MsoNormal" style="
                  margin-bottom: 0in;
                  margin-bottom: 0.0001pt;
                  line-height: normal;
                ">
              <span style="
                    font-size: 12pt;
                    font-family: 'Times New Roman', serif;
                  ">&nbsp;</span>
            </p>
            <p class="MsoNormal" style="
                  margin-bottom: 10pt;
                  text-align: justify;
                  text-justify: inter-ideograph;
                  line-height: 115%;
                ">
              <span style="
                    font-size: 12pt;
                    line-height: 115%;
                    font-family: 'Times New Roman', serif;
                  ">Low-light imaging is often needed for various purposes, such
                as surveillance, photography and autonomous driving. In
                particular for autonomous driving, day-time and night-time
                each roughly contributes to 50% of the time over a year, and
                it is equally important for computer vision techniques
                developed for day-time scenes to work at night-time scenes.
                Unfortunately, low-light images typically contain very dark
                regions, which may suffer from under-exposure problems (i.e.,
                their values are very close to zero), while night-time images
                may suffer from both under-exposure as well as over-exposure
                problems (i.e., their values may be very close to either zero
                or one). Enhancing these images or processing them with
                existing computer vision algorithms often do not work.</span>
            </p>
            <p class="MsoNormal" style="
                  margin-bottom: 10pt;
                  text-align: justify;
                  text-justify: inter-ideograph;
                  line-height: 115%;
                ">
              <span style="
                    font-size: 12pt;
                    line-height: 115%;
                    font-family: 'Times New Roman', serif;
                  ">In this project, we are developing techniques to process
                low-light images. Our research is to address this problem from
                two directions. The first is to consider how to enhance these
                images to improve their visibility. The second is to
                investigate how to improve existing computer vision algorithms
                for direct analyses of low-light images.
              </span>
            </p>
          </td>
        </tr>
        <tr>
          <td width="100%" valign="top" style="
                width: 100%;
                border: none;
                border-bottom: solid windowtext 1.5pt;
                padding: 0in 5.4pt 0in 5.4pt;
              ">
            <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0" width="100%"
              style="width: 100%; border-collapse: collapse; border: none;">
              <tr>
                <td width="100%" valign="top" style="width: 100%; padding: 0in 5.4pt 0in 5.4pt;">
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 0in;
                        margin-left: 0in;
                        margin-bottom: 0.0001pt;
                        line-height: normal;
                      ">
                    <b><span style="font-family: 'Times New Roman', serif;">Learning to Restore Low-light Images via
                        Decomposition-and-Enhancement</span></b><span style="font-family: 'Times New Roman', serif;">
                    </span><span style="
                          font-size: 10pt;
                          font-family: 'Times New Roman', serif;
                        ">[<a href="http://www.cs.cityu.edu.hk/~rynson/papers/cvpr20a.pdf">paper</a>] [<a
                        href="http://www.cs.cityu.edu.hk/~rynson/papers/demos/cvpr20a-supp.pdf">suppl</a>] [model]
                      [dataset]</span>
                  </p>
                  <p class="MsoNormal" style="
                        margin-bottom: 0in;
                        margin-bottom: 0.0001pt;
                        line-height: normal;
                      ">
                    <span style="
                          font-size: 10pt;
                          font-family: 'Times New Roman', serif;
                        ">Ke Xu, Xin Yang*, Baocai Yin, and Rynson Lau
                    </span>
                  </p>
                  <p class="MsoNormal" style="margin-bottom: 6pt; line-height: normal;">
                    <b><i><span style="
                              font-family: 'Times New Roman', serif;
                              color: #c00000;
                            ">Proc. IEEE CVPR (CCF A)</span></i></b><span
                      style="font-family: 'Times New Roman', serif;">, June 2020</span>
                  </p>
                </td>
              </tr>
              <tr>
                <td width="100%" valign="top" style="width: 100%; padding: 0in 5.4pt 0in 5.4pt;">
                  <div align="center">
                    <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0"
                      style="border-collapse: collapse; border: none;">
                      <tr style="height: 142.8pt;">
                        <td width="754" valign="top" style="
                              width: 513.45pt;
                              padding: 0in 5.4pt 0in 5.4pt;
                              height: 142.8pt;
                            ">
                          <p>
                            <img border="0" width="751" src="figures/20200621135331(1).gif" alt="t" />
                          </p>
                          <p class="MsoNormal" align="center" style="
                                margin-bottom: 0in;
                                margin-bottom: 0.0001pt;
                                text-align: center;
                                line-height: normal;
                              ">
                            <span style="
                                  font-size: 9pt;
                                  font-family: 'Times New Roman', serif;
                                "><img border="0" width="739" height="175" id="Picture 2"
                                src="figures/cvpr_2020_results.jpg" /></span>
                          </p>
                          <p class="MsoNormal" style="
                                margin-top: 3pt;
                                margin-right: -2.9pt;
                                margin-bottom: 0in;
                                margin-left: 0in;
                                margin-bottom: 0.0001pt;
                                text-align: justify;
                                text-justify: inter-ideograph;
                                line-height: normal;
                              ">
                            <span style="
                                  font-size: 9pt;
                                  font-family: 'Times New Roman', serif;
                                ">While existing methods ((c) to (j)) generally
                              fail to enhance the input noisy low-light image
                              (a), our method produces a sharper and clearer
                              result with objects and details recovered
                              (l).</span>
                          </p>
                        </td>
                      </tr>
                    </table>
                  </div>
                  <p class="MsoNormal" style="
                        margin-bottom: 0in;
                        margin-bottom: 0.0001pt;
                        line-height: normal;
                        text-autospace: none;
                      "></p>
                </td>
              </tr>
              <tr>
                <td width="100%" valign="top" style="width: 100%; padding: 0in 5.4pt 0in 5.4pt;">
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 6pt;
                        margin-left: 0in;
                        text-align: justify;
                        text-justify: inter-ideograph;
                        line-height: normal;
                        text-autospace: none;
                      ">
                    <b><span style="font-family: 'Times New Roman', serif;">Input-Output:
                      </span></b><span style="font-family: 'Times New Roman', serif;">Given an input practical low-light
                      image, which often
                      comes with a significant amount of noise due to the low
                      signal-to-noise ratio, our network enhances its
                      brightness while at the same time suppressing its noise
                      level, to produce an enhanced clear image.</span>
                  </p>
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 6pt;
                        margin-left: 0in;
                        text-align: justify;
                        text-justify: inter-ideograph;
                        line-height: normal;
                        text-autospace: none;
                      ">
                    <b><span style="font-family: 'Times New Roman', serif;">Abstract.</span></b><span
                      style="font-family: 'Times New Roman', serif;">
                      Low-light images typically suffer from two problems.
                      First, they have low visibility (i.e., small pixel
                      values). Second, noise becomes significant and disrupts
                      the image content, due to low signal-to-noise ratio.
                      Most existing lowlight image enhancement methods,
                      however, learn from noise-negligible datasets. They rely
                      on users having good photographic skills in taking
                      images with low noise. Unfortunately, this is not the
                      case for majority of the low-light images. While
                      concurrently enhancing a low-light image and removing
                      its noise is ill-posed, we observe that noise exhibits
                      different levels of contrast in different frequency
                      layers, and it is much easier to detect noise in the
                      low-frequency layer than in the high one. Inspired by
                      this observation, we propose a frequency-based
                      decomposition-and-enhancement model for low-light image
                      enhancement. Based on this model, we present a novel
                      network that first learns to recover image objects in
                      the low-frequency layer and then enhances high-frequency
                      details based on the recovered image objects. In
                      addition, we have prepared a new low-light image dataset
                      with real noise to facilitate learning. Finally, we have
                      conducted extensive experiments to show that the
                      proposed method outperforms state-of-the-art approaches
                      in enhancing practical noisy low-light images.</span>
                  </p>
                </td>
              </tr>
            </table>
            <p class="MsoNormal" style="
                  margin-bottom: 0in;
                  margin-bottom: 0.0001pt;
                  line-height: normal;
                "></p>
          </td>
        </tr>
        <tr>
          <td width="100%" valign="top" style="
                width: 100%;
                border: none;
                border-bottom: solid windowtext 1.5pt;
                padding: 0in 5.4pt 0in 5.4pt;
              ">
            <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0"
              style="border-collapse: collapse; border: none;">
              <tr>
                <td valign="top" style="padding: 0in 5.4pt 0in 5.4pt;">
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 0in;
                        margin-left: 0in;
                        margin-bottom: 0.0001pt;
                        line-height: normal;
                      ">
                    <b><span style="
                            font-family: 'Times New Roman', serif;
                            color: black;
                          ">Cascaded Network with Deep Intensity Manipulation for
                        Scene Understanding</span></b><span style="font-family: 'Times New Roman', serif;">
                    </span>
                    <!-- div -->
                  </p>
                  <p class="MsoNormal" style="
                        margin-bottom: 0in;
                        margin-bottom: 0.0001pt;
                        line-height: normal;
                      ">
                    <span style="
                          font-size: 10pt;
                          font-family: 'Times New Roman', serif;
                        ">Xin Yang, Haoran Wang, Shaozhe Chen, Xinglin Piao,
                      Dongsheng Zhou, Qiang Zhang, Baocai Yin, Xiaopeng Wei
                    </span>
                  </p>
                  <p class="MsoNormal" style="margin-bottom: 6pt; line-height: normal;">
                    <b><i><span style="
                              font-family: 'Times New Roman', serif;
                              color: #c00000;
                            ">Journal of Visualization and Computer
                          Animation</span></i></b><span style="font-family: 'Times New Roman', serif;">, 30(3-4),
                      2019</span>
                  </p>
                  <div align="center">
                    <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0"
                      style="border-collapse: collapse; border: none;">
                      <tr style="height: 142.8pt;">
                        <td width="766" valign="top" style="
                              width: 513.45pt;
                              padding: 0in 5.4pt 0in 5.4pt;
                              height: 142.8pt;
                            ">
                          <p class="MsoNormal" align="center" style="
                                margin-bottom: 0in;
                                margin-bottom: 0.0001pt;
                                text-align: center;
                                line-height: normal;
                              ">
                            <img border="0" width="751" height="228" id="Picture 3"
                              src="figures/Cascaded Network with Deep Intensity Manipulation for Scene Understanding.png"
                              alt="t" />
                          </p>

                          <p class="MsoNormal" style="
                                margin-top: 3pt;
                                margin-right: -2.9pt;
                                margin-bottom: 0in;
                                margin-left: 0in;
                                margin-bottom: 0.0001pt;
                                text-align: justify;
                                text-justify: inter-ideograph;
                                line-height: normal;
                              ">
                            <span style="
                                  font-size: 9pt;
                                  font-family: 'Times New Roman', serif;
                                ">Limitations of existing enhance algorithms. We
                              choose ICNet to generate segmentation results.
                              The quality of segmentation results is illy
                              influenced by the limited illustration. Existing
                              enhancement algorithms cannot perform
                              optimization and, on the contrary, worsen the
                              segmentation results. (a) Low-light image. (b)
                              Low-light image enhancement via illumination map
                              estimation (LIME). (c) Simultaneous reflectance
                              and illumination estimation (SRIE). (d)
                              Ours</span>
                          </p>
                        </td>
                      </tr>
                    </table>
                  </div>
                  <p class="MsoNormal" style="margin-bottom: 6pt; line-height: normal;"></p>
                </td>
              </tr>
              <tr>
                <td valign="top" style="padding: 0in 5.4pt 0in 5.4pt;">
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 6pt;
                        margin-left: 0in;
                        text-align: justify;
                        text-justify: inter-ideograph;
                        line-height: 115%;
                      ">
                    <b><span style="font-family: 'Times New Roman', serif;">Input-Output:</span></b><span
                      style="font-family: 'Times New Roman', serif;">
                      Given an input low-light image, our network produces an
                      enhanced image with lost details recovered.</span>
                  </p>
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 6pt;
                        margin-left: 0in;
                        text-align: justify;
                        text-justify: inter-ideograph;
                        line-height: normal;
                      ">
                    <b><span style="font-family: 'Times New Roman', serif;">Abstract:</span></b><span
                      style="font-family: 'Times New Roman', serif;">
                      Scene understanding is essential to robotic navigation
                      and autonomous driving as it provides semantic
                      information to their controlling system. However, it
                      will fail when processing low-light images/videos
                      captured under adverse weather or at night use
                      state-of-the-art scene understanding methods. A naive
                      way to directly infer semantics from low-light images is
                      ill posed because the low-light condition distorts pixel
                      intensities and buries details. In order to address this
                      problem, we propose the Deep Intensity Manipulation
                      Network (DIMNet), which could relight the input images
                      and recover the details, and combine the DIMNet with a
                      scene understanding network to get a cascaded network to
                      learn the semantics from low-light images. Through
                      learning pixel intensity manipulation, our method can
                      generate images not only visually pleasing but also
                      practical for scene understanding. Qualitative and
                      quantitative experiments demonstrate that the proposed
                      method is effective and robust for both synthetic and
                      real-world images.</span>
                  </p>
                </td>
              </tr>
            </table>
            <p class="MsoNormal" style="
                  margin-bottom: 0in;
                  margin-bottom: 0.0001pt;
                  line-height: normal;
                "></p>
          </td>
        </tr>
        <tr>
          <td width="100%" valign="top" style="
                width: 100%;
                border: none;
                border-bottom: solid windowtext 1.5pt;
                padding: 0in 5.4pt 0in 5.4pt;
              ">
            <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0"
              style="border-collapse: collapse; border: none;">
              <tr>
                <td valign="top" style="padding: 0in 5.4pt 0in 5.4pt;">
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 0in;
                        margin-left: 0in;
                        margin-bottom: 0.0001pt;
                        line-height: normal;
                      ">
                    <b><span style="
                            font-family: 'Times New Roman', serif;
                            color: black;
                          ">Image Correction via Deep Reciprocating HDR
                        Transformation</span></b><span style="font-family: 'Times New Roman', serif;">
                    </span><span style="
                          font-size: 10pt;
                          font-family: 'Times New Roman', serif;
                        ">[</span><a href="http://www.cs.cityu.edu.hk/~rynson/papers/cvpr18a.pdf"><span style="
                            font-size: 10pt;
                            font-family: 'Times New Roman', serif;
                          ">paper</span></a><span style="
                          font-size: 10pt;
                          font-family: 'Times New Roman', serif;
                        ">] [<a href="http://www.cs.cityu.edu.hk/~rynson/papers/demos/cvpr18asupp.pdf">suppl</a>] [<a
                        href="https://drive.google.com/open?id=1PqZPgBxGw14tukPvtgnPl7qn0Zu6KhTU">code</a>] [<a
                        href="https://drive.google.com/open?id=1lNxf_3LW5b1w5uAvFVLJE5By01OmXRXI">dataset</a>]</span>
                  </p>
                  <p class="MsoNormal" style="
                        margin-bottom: 0in;
                        margin-bottom: 0.0001pt;
                        line-height: normal;
                      ">
                    <span style="
                          font-size: 10pt;
                          font-family: 'Times New Roman', serif;
                        ">Xin Yang, Ke Xu, Yibing Song, Qiang Zhang, Xiaopeng
                      Wei, and Rynson Lau
                    </span>
                  </p>
                  <p class="MsoNormal" style="margin-bottom: 6pt; line-height: normal;">
                    <b><i><span style="
                              font-family: 'Times New Roman', serif;
                              color: #c00000;
                            ">Proc. IEEE CVPR (CCF A)</span></i></b><span
                      style="font-family: 'Times New Roman', serif;">, June 2018</span>
                  </p>
                  <div align="center">
                    <table class="MsoTableGrid" border="0" cellspacing="0" cellpadding="0"
                      style="border-collapse: collapse; border: none;">
                      <tr style="height: 142.8pt;">
                        <td width="766" valign="top" style="
                              width: 513.45pt;
                              padding: 0in 5.4pt 0in 5.4pt;
                              height: 142.8pt;
                            ">
                          <p>
                            <img border="0" width="751" src="figures/20200621135331(2).gif" alt="t" />
                          </p>
                          <p class="MsoNormal" align="center" style="
                                margin-bottom: 0in;
                                margin-bottom: 0.0001pt;
                                text-align: center;
                                line-height: normal;
                              ">
                            <img border="0" width="751" height="228" id="Picture 4" src="figures/cvpr_2018_results.jpg"
                              alt="t" />
                          </p>

                          <p class="MsoNormal" style="
                                margin-top: 3pt;
                                margin-right: -2.9pt;
                                margin-bottom: 0in;
                                margin-left: 0in;
                                margin-bottom: 0.0001pt;
                                text-align: justify;
                                text-justify: inter-ideograph;
                                line-height: normal;
                              ">
                            <span style="
                                  font-size: 9pt;
                                  font-family: 'Times New Roman', serif;
                                ">Image correction results on an underexposed
                              input. Existing LDR methods have the limitation
                              in recovering the missing details, as shown in
                              (b)-(f). In comparison, we recover the missing
                              LDR details in the HDR domain and preserve them
                              through tone mapping, producing a more favorable
                              result as shown in (g).</span>
                          </p>
                        </td>
                      </tr>
                    </table>
                  </div>
                  <p class="MsoNormal" style="margin-bottom: 6pt; line-height: normal;"></p>
                </td>
              </tr>
              <tr>
                <td valign="top" style="padding: 0in 5.4pt 0in 5.4pt;">
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 6pt;
                        margin-left: 0in;
                        text-align: justify;
                        text-justify: inter-ideograph;
                        line-height: 115%;
                      ">
                    <b><span style="font-family: 'Times New Roman', serif;">Input-Output:</span></b><span
                      style="font-family: 'Times New Roman', serif;">
                      Given an input low-light image, our network produces an
                      enhanced image with lost details recovered.</span>
                  </p>
                  <p class="MsoNormal" style="
                        margin-top: 6pt;
                        margin-right: 0in;
                        margin-bottom: 6pt;
                        margin-left: 0in;
                        text-align: justify;
                        text-justify: inter-ideograph;
                        line-height: normal;
                      ">
                    <b><span style="font-family: 'Times New Roman', serif;">Abstract:</span></b><span
                      style="font-family: 'Times New Roman', serif;">
                      Image correction aims to adjust an input image into a
                      visually pleasing one. Existing approaches are proposed
                      mainly from the perspective of image pixel manipulation.
                      They are not effective to recover the details in the
                      under/over exposed regions. In this paper, we revisit
                      the image formation procedure and notice that the
                      missing details in these regions exist in the
                      corresponding high dynamic range (HDR) data. These
                      details are well perceived by the human eyes but
                      diminished in the low dynamic range (LDR) domain because
                      of the tone mapping process. Therefore, we formulate the
                      image correction task as an HDR transformation process
                      and propose a novel approach called Deep Reciprocating
                      HDR Transformation (DRHT). Given an input LDR image, we
                      first reconstruct the missing details in the HDR domain.
                      We then perform tone mapping on the predicted HDR data
                      to generate the output LDR image with the recovered
                      details. To this end, we propose a united framework
                      consisting of two CNNs for HDR reconstruction and tone
                      mapping. They are integrated end-to-end for joint
                      training and prediction. Experiments on the standard
                      benchmarks demonstrate that the proposed method performs
                      favorably against state-of-the-art image correction
                      methods.</span>
                  </p>
                </td>
              </tr>
            </table>
            <p class="MsoNormal" style="
                  margin-bottom: 0in;
                  margin-bottom: 0.0001pt;
                  line-height: normal;
                "></p>
          </td>
        </tr>
      </table>
    </div>
    <img src="https://www.cs.cityu.edu.hk/~rynson/count/counter.cgi?t" width="1" height="1" />
    <p class="MsoNormal" style="
          margin-top: 6pt;
          margin-right: 0in;
          margin-bottom: 0in;
          margin-left: 0in;
          margin-bottom: 0.0001pt;
        ">
      <i><span style="
              font-size: 9pt;
              line-height: 115%;
              font-family: 'Times New Roman', serif;
            ">Last updated in March 2020</span></i>
    </p>
  </div>
</body>
<script>
  new Vue({
    el: "#app",
    methods: {
      goBack() {
        window.location.href = "../index.html#Research Projects";
      },
    },
  });
</script>

</html>